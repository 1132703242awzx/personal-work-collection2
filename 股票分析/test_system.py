"""
è‚¡ç¥¨åˆ†æç³»ç»Ÿæµ‹è¯•è„šæœ¬
ç”¨äºéªŒè¯å„ä¸ªæ¨¡å—çš„åŠŸèƒ½
"""

import sys
import os
import unittest
import pandas as pd
import numpy as np
import torch
from datetime import datetime, timedelta

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.append('d:/è‚¡ç¥¨åˆ†æ')

from data_crawler import StockDataCrawler
from rcsan_model import StockPredictor, RCSAN
from visualizer import StockVisualizer

class TestStockAnalysisSystem(unittest.TestCase):
    """æµ‹è¯•è‚¡ç¥¨åˆ†æç³»ç»Ÿ"""
    
    def setUp(self):
        """æµ‹è¯•å‰è®¾ç½®"""
        print(f"\n{'='*60}")
        print(f"ğŸ§ª å¼€å§‹æµ‹è¯•: {self._testMethodName}")
        print(f"{'='*60}")
        
        # åˆ›å»ºæµ‹è¯•æ•°æ®
        self.test_data = self.create_test_data()
        self.stock_code = "000001"
        
    def create_test_data(self):
        """åˆ›å»ºæµ‹è¯•æ•°æ®"""
        dates = pd.date_range(start='2023-01-01', periods=150)
        np.random.seed(42)  # ç¡®ä¿ç»“æœå¯é‡ç°
        
        # æ¨¡æ‹Ÿè‚¡ä»·èµ°åŠ¿
        base_price = 10.0
        price_changes = np.random.normal(0, 0.02, 150)
        prices = [base_price]
        
        for change in price_changes[:-1]:
            new_price = prices[-1] * (1 + change)
            prices.append(max(new_price, 0.1))  # ç¡®ä¿ä»·æ ¼ä¸ºæ­£
        
        data = pd.DataFrame({
            'date': dates,
            'open': [p * (1 + np.random.normal(0, 0.005)) for p in prices],
            'close': prices,
            'high': [p * (1 + abs(np.random.normal(0, 0.01))) for p in prices],
            'low': [p * (1 - abs(np.random.normal(0, 0.01))) for p in prices],
            'volume': np.random.randint(1000000, 10000000, 150),
            'amount': np.random.uniform(10000000, 100000000, 150)
        })
        
        return data
    
    def test_data_crawler(self):
        """æµ‹è¯•æ•°æ®çˆ¬è™«åŠŸèƒ½"""
        print("ğŸ“Š æµ‹è¯•æ•°æ®çˆ¬è™«...")
        
        crawler = StockDataCrawler()
        
        # æµ‹è¯•è‚¡ç¥¨ä»£ç æ ¼å¼åŒ–
        self.assertEqual(crawler.get_stock_code_format("600000"), "sh600000")
        self.assertEqual(crawler.get_stock_code_format("000001"), "sz000001")
        print("âœ… è‚¡ç¥¨ä»£ç æ ¼å¼åŒ–æµ‹è¯•é€šè¿‡")
        
        # æµ‹è¯•æŠ€æœ¯æŒ‡æ ‡è®¡ç®—
        data_with_indicators = crawler.add_technical_indicators(self.test_data.copy())
        
        expected_columns = ['ma5', 'ma10', 'ma20', 'ma60', 'rsi', 'macd', 'macd_signal', 'macd_hist']
        for col in expected_columns:
            self.assertIn(col, data_with_indicators.columns)
        
        print("âœ… æŠ€æœ¯æŒ‡æ ‡è®¡ç®—æµ‹è¯•é€šè¿‡")
        print(f"   æ·»åŠ äº† {len(expected_columns)} ä¸ªæŠ€æœ¯æŒ‡æ ‡")
        
    def test_rcsan_model(self):
        """æµ‹è¯•R-CSANæ¨¡å‹"""
        print("ğŸ§  æµ‹è¯•R-CSANæ¨¡å‹...")
        
        # æµ‹è¯•æ¨¡å‹åˆ›å»º
        model = RCSAN(input_features=10, sequence_length=30, prediction_days=7)
        self.assertIsNotNone(model)
        print("âœ… æ¨¡å‹åˆ›å»ºæˆåŠŸ")
        
        # æµ‹è¯•å‰å‘ä¼ æ’­
        batch_size = 4
        sequence_length = 30
        input_features = 10
        
        test_input = torch.randn(batch_size, sequence_length, input_features)
        
        model.eval()
        with torch.no_grad():
            output = model(test_input)
        
        self.assertEqual(output.shape, (batch_size, 7))
        print(f"âœ… å‰å‘ä¼ æ’­æµ‹è¯•é€šè¿‡ï¼Œè¾“å‡ºå½¢çŠ¶: {output.shape}")
        
        # æµ‹è¯•æ¨¡å‹å‚æ•°æ•°é‡
        param_count = sum(p.numel() for p in model.parameters())
        print(f"   æ¨¡å‹å‚æ•°æ•°é‡: {param_count:,}")
        
    def test_stock_predictor(self):
        """æµ‹è¯•è‚¡ç¥¨é¢„æµ‹å™¨"""
        print("ğŸ”® æµ‹è¯•è‚¡ç¥¨é¢„æµ‹å™¨...")
        
        # æ·»åŠ æŠ€æœ¯æŒ‡æ ‡
        crawler = StockDataCrawler()
        data_with_indicators = crawler.add_technical_indicators(self.test_data.copy())
        
        # åˆ›å»ºé¢„æµ‹å™¨
        predictor = StockPredictor(input_features=14, sequence_length=30, prediction_days=7)
        self.assertIsNotNone(predictor)
        print("âœ… é¢„æµ‹å™¨åˆ›å»ºæˆåŠŸ")
        
        # æµ‹è¯•æ•°æ®å‡†å¤‡
        X, y = predictor.prepare_data(data_with_indicators)
        
        self.assertGreater(X.shape[0], 0)
        self.assertEqual(X.shape[1], 30)  # sequence_length
        self.assertEqual(y.shape[1], 7)   # prediction_days
        
        print(f"âœ… æ•°æ®å‡†å¤‡æµ‹è¯•é€šè¿‡")
        print(f"   è®­ç»ƒæ ·æœ¬æ•°: {X.shape[0]}")
        print(f"   è¾“å…¥ç‰¹å¾æ•°: {X.shape[2]}")
        
        # æµ‹è¯•å°è§„æ¨¡è®­ç»ƒ
        print("   è¿›è¡Œå°è§„æ¨¡è®­ç»ƒæµ‹è¯•...")
        try:
            predictor.train((X, y), epochs=5, batch_size=4)
            print("âœ… è®­ç»ƒæµç¨‹æµ‹è¯•é€šè¿‡")
        except Exception as e:
            print(f"âš ï¸ è®­ç»ƒæµ‹è¯•è­¦å‘Š: {str(e)}")
        
        # æµ‹è¯•é¢„æµ‹
        test_input = X[:1]  # å–ä¸€ä¸ªæ ·æœ¬
        predictions = predictor.predict(test_input)
        
        self.assertEqual(len(predictions[0]), 7)
        print(f"âœ… é¢„æµ‹åŠŸèƒ½æµ‹è¯•é€šè¿‡ï¼Œé¢„æµ‹ç»“æœ: {predictions[0]}")
        
    def test_visualizer(self):
        """æµ‹è¯•å¯è§†åŒ–æ¨¡å—"""
        print("ğŸ¨ æµ‹è¯•å¯è§†åŒ–æ¨¡å—...")
        
        visualizer = StockVisualizer()
        self.assertIsNotNone(visualizer)
        print("âœ… å¯è§†åŒ–å™¨åˆ›å»ºæˆåŠŸ")
        
        # æ·»åŠ æŠ€æœ¯æŒ‡æ ‡ç”¨äºæµ‹è¯•
        crawler = StockDataCrawler()
        data_with_indicators = crawler.add_technical_indicators(self.test_data.copy())
        
        # æµ‹è¯•é¢„æµ‹æŠ¥å‘Šç”Ÿæˆ
        test_predictions = [10.5, 10.3, 10.7, 10.8, 10.6, 10.9, 11.0]
        
        try:
            report = visualizer.create_prediction_report(
                data_with_indicators, test_predictions, self.stock_code
            )
            self.assertIsNotNone(report)
            self.assertIn("è‚¡ç¥¨é¢„æµ‹æŠ¥å‘Š", report)
            print("âœ… é¢„æµ‹æŠ¥å‘Šç”Ÿæˆæµ‹è¯•é€šè¿‡")
        except Exception as e:
            print(f"âš ï¸ é¢„æµ‹æŠ¥å‘Šæµ‹è¯•è­¦å‘Š: {str(e)}")
        
        print("âœ… å¯è§†åŒ–æ¨¡å—åŸºç¡€åŠŸèƒ½æµ‹è¯•é€šè¿‡")
        
    def test_integration(self):
        """æµ‹è¯•ç³»ç»Ÿé›†æˆ"""
        print("ğŸ”— æµ‹è¯•ç³»ç»Ÿé›†æˆ...")
        
        try:
            # 1. æ•°æ®å¤„ç†
            crawler = StockDataCrawler()
            data_with_indicators = crawler.add_technical_indicators(self.test_data.copy())
            print("âœ… æ•°æ®å¤„ç†é›†æˆæˆåŠŸ")
            
            # 2. æ¨¡å‹è®­ç»ƒ
            predictor = StockPredictor(input_features=14, sequence_length=30, prediction_days=7)
            X, y = predictor.prepare_data(data_with_indicators)
            
            # å¿«é€Ÿè®­ç»ƒæµ‹è¯•
            predictor.train((X, y), epochs=3, batch_size=4)
            print("âœ… æ¨¡å‹è®­ç»ƒé›†æˆæˆåŠŸ")
            
            # 3. é¢„æµ‹
            predictions = predictor.predict(X[:1])
            print("âœ… æ¨¡å‹é¢„æµ‹é›†æˆæˆåŠŸ")
            
            # 4. å¯è§†åŒ–
            visualizer = StockVisualizer()
            report = visualizer.create_prediction_report(
                data_with_indicators, predictions[0], self.stock_code
            )
            print("âœ… å¯è§†åŒ–é›†æˆæˆåŠŸ")
            
            print("ğŸ‰ ç³»ç»Ÿé›†æˆæµ‹è¯•å…¨éƒ¨é€šè¿‡ï¼")
            
        except Exception as e:
            self.fail(f"ç³»ç»Ÿé›†æˆæµ‹è¯•å¤±è´¥: {str(e)}")
    
    def tearDown(self):
        """æµ‹è¯•åæ¸…ç†"""
        print(f"âœ… æµ‹è¯• {self._testMethodName} å®Œæˆ")

def run_performance_test():
    """è¿è¡Œæ€§èƒ½æµ‹è¯•"""
    print(f"\n{'='*60}")
    print("âš¡ æ€§èƒ½æµ‹è¯•")
    print(f"{'='*60}")
    
    import time
    
    # åˆ›å»ºå¤§è§„æ¨¡æµ‹è¯•æ•°æ®
    dates = pd.date_range(start='2020-01-01', periods=500)
    np.random.seed(42)
    
    large_data = pd.DataFrame({
        'date': dates,
        'open': np.random.uniform(8, 12, 500),
        'close': np.random.uniform(8, 12, 500),
        'high': np.random.uniform(10, 15, 500),
        'low': np.random.uniform(5, 10, 500),
        'volume': np.random.randint(1000000, 50000000, 500),
        'amount': np.random.uniform(10000000, 500000000, 500)
    })
    
    # æ€§èƒ½æµ‹è¯•ï¼šæ•°æ®å¤„ç†
    start_time = time.time()
    crawler = StockDataCrawler()
    data_with_indicators = crawler.add_technical_indicators(large_data)
    processing_time = time.time() - start_time
    print(f"ğŸ“Š æ•°æ®å¤„ç†æ—¶é—´: {processing_time:.2f}ç§’ (500æ¡æ•°æ®)")
    
    # æ€§èƒ½æµ‹è¯•ï¼šæ¨¡å‹è®­ç»ƒ
    start_time = time.time()
    predictor = StockPredictor(input_features=14, sequence_length=60, prediction_days=7)
    X, y = predictor.prepare_data(data_with_indicators)
    data_prep_time = time.time() - start_time
    print(f"ğŸ”„ æ•°æ®å‡†å¤‡æ—¶é—´: {data_prep_time:.2f}ç§’ ({X.shape[0]}ä¸ªæ ·æœ¬)")
    
    # å°è§„æ¨¡è®­ç»ƒæµ‹è¯•
    start_time = time.time()
    predictor.train((X, y), epochs=5, batch_size=8)
    training_time = time.time() - start_time
    print(f"ğŸ§  æ¨¡å‹è®­ç»ƒæ—¶é—´: {training_time:.2f}ç§’ (5ä¸ªepoch)")
    
    # é¢„æµ‹æ€§èƒ½æµ‹è¯•
    start_time = time.time()
    predictions = predictor.predict(X[:10])
    prediction_time = time.time() - start_time
    print(f"ğŸ”® é¢„æµ‹æ—¶é—´: {prediction_time:.2f}ç§’ (10ä¸ªæ ·æœ¬)")
    
    print("âš¡ æ€§èƒ½æµ‹è¯•å®Œæˆ")

def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("ğŸš€ è‚¡ç¥¨åˆ†æç³»ç»Ÿæµ‹è¯•å¥—ä»¶")
    print(f"æµ‹è¯•æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    
    # æ£€æŸ¥PyTorch
    print(f"PyTorchç‰ˆæœ¬: {torch.__version__}")
    print(f"CUDAå¯ç”¨: {torch.cuda.is_available()}")
    print(f"è®¾å¤‡: {'GPU' if torch.cuda.is_available() else 'CPU'}")
    
    # è¿è¡Œå•å…ƒæµ‹è¯•
    print(f"\n{'='*60}")
    print("ğŸ§ª å¼€å§‹å•å…ƒæµ‹è¯•")
    print(f"{'='*60}")
    
    # åˆ›å»ºæµ‹è¯•å¥—ä»¶
    test_suite = unittest.TestLoader().loadTestsFromTestCase(TestStockAnalysisSystem)
    
    # è¿è¡Œæµ‹è¯•
    runner = unittest.TextTestRunner(verbosity=2)
    result = runner.run(test_suite)
    
    # æ˜¾ç¤ºæµ‹è¯•ç»“æœ
    print(f"\n{'='*60}")
    print("ğŸ“Š æµ‹è¯•ç»“æœç»Ÿè®¡")
    print(f"{'='*60}")
    print(f"æ€»æµ‹è¯•æ•°: {result.testsRun}")
    print(f"æˆåŠŸ: {result.testsRun - len(result.failures) - len(result.errors)}")
    print(f"å¤±è´¥: {len(result.failures)}")
    print(f"é”™è¯¯: {len(result.errors)}")
    
    if result.failures:
        print("\nâŒ å¤±è´¥çš„æµ‹è¯•:")
        for test, traceback in result.failures:
            print(f"  - {test}: {traceback}")
    
    if result.errors:
        print("\nâš ï¸ é”™è¯¯çš„æµ‹è¯•:")
        for test, traceback in result.errors:
            print(f"  - {test}: {traceback}")
    
    # è¿è¡Œæ€§èƒ½æµ‹è¯•
    if result.testsRun > 0 and len(result.failures) == 0 and len(result.errors) == 0:
        run_performance_test()
    
    # æ€»ç»“
    print(f"\n{'='*60}")
    if len(result.failures) == 0 and len(result.errors) == 0:
        print("ğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼ç³»ç»Ÿè¿è¡Œæ­£å¸¸ã€‚")
    else:
        print("âš ï¸ éƒ¨åˆ†æµ‹è¯•æœªé€šè¿‡ï¼Œè¯·æ£€æŸ¥ç³»ç»Ÿé…ç½®ã€‚")
    print(f"{'='*60}")

if __name__ == "__main__":
    main()
